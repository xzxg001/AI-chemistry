{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFkzxuXl41QO"
   },
   "source": [
    "# 安装环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "G_paPcK-41QP"
   },
   "outputs": [],
   "source": [
    "# # !pip install torchtext\n",
    "# !pip install pandas\n",
    "# !pip install scikit-optimize\n",
    "# !pip install torch torchvision\n",
    "# # !git clone https://github.com/xzxg001/AI-chemistry.git\n",
    "# !pip3 install torch==2.1.0 # 对于 x86 平台 pip3 install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip3 install pyyaml \n",
    "# !pip3 install setuptools\n",
    "# !pip3 install torch-npu==2.1.0.post8\n",
    "!export PYTHONPATH=usr/local/Ascend/ascend-toolkit/8.0.RC1/aarch64-linux/ascend-toolkit/latest/tools/ms_fmk_transplt/torch_npu_bridge:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spoEXJ9141QQ"
   },
   "source": [
    "# 对数据处理进行初步尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "24CkVmGX41QQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : ASCEND_HOME_PATH environment variable is not set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch_npu/__init__.py:234: UserWarning: On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default.                      Do not set it to 1 to prevent some unknown errors\n",
      "  warnings.warn(\"On the interactive interface, the value of TASK_QUEUE_ENABLE is set to 0 by default. \\\n",
      "/usr/local/Ascend/ascend-toolkit/latest/tools/ms_fmk_transplt/torch_npu_bridge/transfer_to_npu.py:223: ImportWarning: \n",
      "    *************************************************************************************************************\n",
      "    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..\n",
      "    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..\n",
      "    The backend in torch.distributed.init_process_group set to hccl now..\n",
      "    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..\n",
      "    The device parameters have been replaced with npu in the function below:\n",
      "    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty\n",
      "    *************************************************************************************************************\n",
      "    \n",
      "  warnings.warn(msg, ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch_npu\n",
    "import transfer_to_npu\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_npu\n",
    "from torch_npu.npu import amp\n",
    "device=torch.device('npu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4jNsCZYC41QR"
   },
   "outputs": [],
   "source": [
    "# tokenizer，鉴于SMILES的特性，这里需要自己定义tokenizer和vocab\n",
    "# 这里直接将smiles str按字符拆分，并替换为词汇表中的序号\n",
    "class Smiles_tokenizer():\n",
    "    def __init__(self, pad_token, regex, vocab_file, max_length):\n",
    "        self.pad_token = pad_token\n",
    "        self.regex = regex\n",
    "        self.vocab_file = vocab_file\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(self.vocab_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [line.strip(\"\\n\") for line in lines]\n",
    "        vocab_dic = {}\n",
    "        for index, token in enumerate(lines):\n",
    "            vocab_dic[token] = index\n",
    "        self.vocab_dic = vocab_dic\n",
    "\n",
    "    def _regex_match(self, smiles):\n",
    "        regex_string = r\"(\" + self.regex + r\"|\"\n",
    "        regex_string += r\".)\"\n",
    "        prog = re.compile(regex_string)\n",
    "\n",
    "        tokenised = []\n",
    "        for smi in smiles:\n",
    "            tokens = prog.findall(smi)\n",
    "            if len(tokens) > self.max_length:\n",
    "                tokens = tokens[:self.max_length]\n",
    "            tokenised.append(tokens) # 返回一个所有的字符串列表\n",
    "        return tokenised\n",
    "\n",
    "    def tokenize(self, smiles):\n",
    "        tokens = self._regex_match(smiles)\n",
    "        # 添加上表示开始和结束的token：<cls>, <end>\n",
    "        tokens = [[\"<CLS>\"] + token + [\"<SEP>\"] for token in tokens]\n",
    "        tokens = self._pad_seqs(tokens, self.pad_token)\n",
    "        token_idx = self._pad_token_to_idx(tokens)\n",
    "        return tokens, token_idx\n",
    "\n",
    "    def _pad_seqs(self, seqs, pad_token):\n",
    "        pad_length = max([len(seq) for seq in seqs])\n",
    "        padded = [seq + ([pad_token] * (pad_length - len(seq))) for seq in seqs]\n",
    "        return padded\n",
    "\n",
    "    def _pad_token_to_idx(self, tokens):\n",
    "        idx_list = []\n",
    "        new_vocab = []\n",
    "        for token in tokens:\n",
    "            tokens_idx = []\n",
    "            for i in token:\n",
    "                if i in self.vocab_dic.keys():\n",
    "                    tokens_idx.append(self.vocab_dic[i])\n",
    "                else:\n",
    "                    new_vocab.append(i)\n",
    "                    self.vocab_dic[i] = max(self.vocab_dic.values()) + 1\n",
    "                    tokens_idx.append(self.vocab_dic[i])\n",
    "            idx_list.append(tokens_idx)\n",
    "\n",
    "        with open(\"../new_vocab_list.txt\", \"a\") as f:\n",
    "            for i in new_vocab:\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        return idx_list\n",
    "\n",
    "    def _save_vocab(self, vocab_path):\n",
    "        with open(vocab_path, \"w\") as f:\n",
    "            for i in self.vocab_dic.keys():\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "        print(\"update new vocab!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rHPpF6GQ41QR"
   },
   "outputs": [],
   "source": [
    "# 处理数据\n",
    "\n",
    "def read_data(file_path, train=True):\n",
    "    df = pd.read_csv(file_path)\n",
    "    reactant1 = df[\"Reactant1\"].tolist()\n",
    "    reactant2 = df[\"Reactant2\"].tolist()\n",
    "    product = df[\"Product\"].tolist()\n",
    "    additive = df[\"Additive\"].tolist()\n",
    "    solvent = df[\"Solvent\"].tolist()\n",
    "    if train:\n",
    "        react_yield = df[\"Yield\"].tolist()\n",
    "    else:\n",
    "        react_yield = [0 for i in range(len(reactant1))]\n",
    "\n",
    "    # 将reactant\\additive\\solvent拼到一起，之间用.分开。product也拼到一起，用>>分开\n",
    "    input_data_list = []\n",
    "    for react1, react2, prod, addi, sol in zip(reactant1, reactant2, product, additive, solvent):\n",
    "        # input_info = \".\".join([react1, react2, addi, sol])\n",
    "        input_info = \".\".join([react1, react2])\n",
    "        input_info = \">\".join([input_info, prod])\n",
    "        input_data_list.append(input_info)\n",
    "    output = [(react, y) for react, y in zip(input_data_list, react_yield)]\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "omfbLOUW41QR"
   },
   "outputs": [],
   "source": [
    "# 定义数据集\n",
    "class ReactionDataset(Dataset):\n",
    "    def __init__(self, data: List[Tuple[List[str], float]]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    REGEX = r\"\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]\"\n",
    "    tokenizer = Smiles_tokenizer(\"<PAD>\", REGEX, \"/home/ma-user/work/AI-chemistry/mp/vocab_full.txt\", 300)\n",
    "    smi_list = []\n",
    "    yield_list = []\n",
    "    for i in batch:\n",
    "        smi_list.append(i[0])\n",
    "        yield_list.append(i[1])\n",
    "    tokenizer_batch = torch.tensor(tokenizer.tokenize(smi_list)[1])\n",
    "    yield_list = torch.tensor(yield_list)\n",
    "    return tokenizer_batch, yield_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "faUZr4-F41QS"
   },
   "outputs": [],
   "source": [
    "# 模型\n",
    "'''\n",
    "直接采用一个transformer encoder model就好了\n",
    "'''\n",
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, num_heads, fnn_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, d_model)\n",
    "        self.layerNorm = nn.LayerNorm(d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model,\n",
    "                                                        nhead=num_heads,\n",
    "                                                        dim_feedforward=fnn_dim,\n",
    "                                                        dropout=dropout,\n",
    "                                                        batch_first=True,\n",
    "                                                        norm_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer,\n",
    "                                                         num_layers=num_layers,\n",
    "                                                         enable_nested_tensor=False,\n",
    "                                                         norm=self.layerNorm)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lc = nn.Sequential(nn.Linear(d_model, 256),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(256, 96),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(96, 1))\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs = self.transformer_encoder(embedded)\n",
    "        z = outputs[:,0,:]\n",
    "        outputs = self.lc(z)\n",
    "        return outputs.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XDv4kJyW41QS"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, start_lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = start_lr * (0.1 ** (epoch // 3))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8hk_Uv341QS",
    "outputId": "10d4d30f-dab5-4cd9-b940-f09cd2648393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Ascend/ascend-toolkit/8.0.RC1/python/site-packages/tbe/tvm/contrib/ccec.py:792: DeprecationWarning: invalid escape sequence \\L\n",
      "  if not dirpath.find(\"AppData\\Local\\Temp\"):\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \\B\n",
      "  \"\"\"\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:143: DeprecationWarning: invalid escape sequence \\c\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model found. Training from scratch.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "call aclnnFlashAttentionScore failed, detail:EZ9999: Inner Error!\nEZ9999: 2024-12-07-23:22:08.380.296  Cannot find bin of op FlashAttentionScore, integral key 0/1/|float/ND/float/ND/float/ND/float/ND/float/ND/float/ND/float/ND/.\n        TraceBack (most recent call last):\n        Cannot find binary for op FlashAttentionScore.\n        Kernel GetWorkspace failed. opType: 100\n        Kernel Run failed. opType: 100, FlashAttentionScore\n        launch failed for FlashAttentionScore, errno:561000.\n\n[ERROR] 2024-12-07-23:22:08 (PID:1627011, Device:0, RankID:-1) ERR01100 OPS call acl api failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model_file, device)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_HEADS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFNN_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_LAYERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDROPOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# 如果模型已加载，可以在这里添加测试或其他操作\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, valid_loader, model_file, N_EPOCHS, LR, CLIP, INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT)\u001b[0m\n\u001b[1;32m     37\u001b[0m src, y \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 39\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 29\u001b[0m, in \u001b[0;36mTransformerEncoderModel.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src):\n\u001b[1;32m     28\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(src))\n\u001b[0;32m---> 29\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     z \u001b[38;5;241m=\u001b[39m outputs[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[1;32m     31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlc(z)\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/transformer.py:704\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    702\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n\u001b[0;32m--> 704\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/python-3.9.10/lib/python3.9/site-packages/torch/nn/functional.py:5440\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5437\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5438\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5441\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5443\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: call aclnnFlashAttentionScore failed, detail:EZ9999: Inner Error!\nEZ9999: 2024-12-07-23:22:08.380.296  Cannot find bin of op FlashAttentionScore, integral key 0/1/|float/ND/float/ND/float/ND/float/ND/float/ND/float/ND/float/ND/.\n        TraceBack (most recent call last):\n        Cannot find binary for op FlashAttentionScore.\n        Kernel GetWorkspace failed. opType: 100\n        Kernel Run failed. opType: 100, FlashAttentionScore\n        launch failed for FlashAttentionScore, errno:561000.\n\n[ERROR] 2024-12-07-23:22:08 (PID:1627011, Device:0, RankID:-1) ERR01100 OPS call acl api failed"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "import os\n",
    "\n",
    "def prepare_data(data_path, batch_size, test_size=0.1, valid_size=0.1):\n",
    "    data = read_data(data_path)\n",
    "    dataset = ReactionDataset(data)\n",
    "\n",
    "    # 确保测试集和验证集的大小加起来不超过数据集大小\n",
    "    test_size = int(len(dataset) * test_size)\n",
    "    valid_size = int(len(dataset) * valid_size)\n",
    "\n",
    "    # 计算训练集的大小，确保总和等于数据集大小\n",
    "    train_size = len(dataset) - test_size - valid_size\n",
    "\n",
    "    # 分割数据集\n",
    "    train_dataset, valid_test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "    valid_dataset, test_dataset = random_split(valid_test_dataset, [valid_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def train(train_loader, valid_loader, model_file, N_EPOCHS, LR, CLIP, INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TransformerEncoderModel(INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT).to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR, weight_decay=0.01)    # 定义优化器\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    criterion = nn.MSELoss()\n",
    "    scaler = amp.GradScaler()    # 在模型、优化器定义之后，定义GradScaler\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        total_loss = 0\n",
    "        for i, (src, y) in enumerate(train_loader):\n",
    "            src, y = src.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {average_loss:.3f}')\n",
    "        scheduler.step(average_loss)\n",
    "\n",
    "        # 计算验证损失\n",
    "        valid_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for src, y in valid_loader:\n",
    "                src, y = src.to(device), y.to(device)\n",
    "                output = model(src)\n",
    "                valid_loss += criterion(output, y).item()\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        print(f'Epoch: {epoch+1:02} | Valid Loss: {valid_loss:.3f}')\n",
    "        model.train()\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_file, device):\n",
    "    model = TransformerEncoderModel(INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT).to(device)\n",
    "    if os.path.exists(model_file):\n",
    "        model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "        model.eval()\n",
    "        print(f\"Model loaded from {model_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No existing model found. Training from scratch.\")\n",
    "        return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 设置参数\n",
    "    batch_size = 128\n",
    "    N_EPOCHS = 40\n",
    "    LR = 1e-4\n",
    "    CLIP = 1\n",
    "    INPUT_DIM = 292\n",
    "    D_MODEL = 512\n",
    "    NUM_HEADS = 4\n",
    "    FNN_DIM = 1024\n",
    "    NUM_LAYERS = 4\n",
    "    DROPOUT = 0.2\n",
    "    # device = torch.device('npu:{}'.format(args.gpu))\n",
    "    # model.npu(args.gpu)\n",
    "    model_file = \"/home/ma-user/modelarts/user-job-dir/model/transformer.pth\"\n",
    "\n",
    "    train_loader, valid_loader, test_loader = prepare_data(\"/home/ma-user/work/AI-chemistry/mp/dataset/train_data.csv\", batch_size)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = load_model(model_file, device)\n",
    "\n",
    "    if model is None:\n",
    "        train(train_loader, valid_loader, model_file, N_EPOCHS, LR, CLIP, INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT)\n",
    "    else:\n",
    "        # 如果模型已加载，可以在这里添加测试或其他操作\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpQZSJUh41QS",
    "outputId": "6acf0520-22b4-4463-a846-353d8d478dd9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_mse_loss = 0\n",
    "    total_mae_loss = 0\n",
    "    total_r2 = 0\n",
    "    total_count = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, y in test_loader:\n",
    "            src, y = src.to(device), y.to(device)\n",
    "            output = model(src)\n",
    "            mse_loss = nn.MSELoss()(output, y)\n",
    "            mae_loss = nn.L1Loss()(output, y)\n",
    "            r2 = r2_score(y.cpu().numpy(), output.cpu().numpy())  # 计算 R-squared\n",
    "            total_mse_loss += mse_loss.item() * len(y)\n",
    "            total_mae_loss += mae_loss.item() * len(y)\n",
    "            total_r2 += r2 * len(y)\n",
    "            total_count += len(y)\n",
    "\n",
    "            # 保存所有预测和目标值用于整体 R-squared 计算\n",
    "            all_predictions.extend(output.cpu().numpy().flatten())\n",
    "            all_targets.extend(y.cpu().numpy().flatten())\n",
    "\n",
    "    avg_mse_loss = total_mse_loss / total_count if total_count > 0 else 0\n",
    "    avg_mae_loss = total_mae_loss / total_count if total_count > 0 else 0\n",
    "    avg_r2 = total_r2 / total_count if total_count > 0 else 0\n",
    "\n",
    "    # 计算 RMSE\n",
    "    rmse = (mean_squared_error(all_targets, all_predictions, squared=False)) if total_count > 0 else 0\n",
    "\n",
    "    print(f'Test MSE Loss: {avg_mse_loss:.3f}')\n",
    "    print(f'Test MAE Loss: {avg_mae_loss:.3f}')\n",
    "    print(f'Test R-squared: {avg_r2:.3f}')\n",
    "    print(f'Test RMSE: {rmse:.3f}')\n",
    "\n",
    "    return avg_mse_loss, avg_mae_loss, avg_r2, rmse\n",
    "# 加载模型并测试\n",
    "def load_and_test(model_file, test_loader, INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TransformerEncoderModel(INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT).to(device)\n",
    "    if os.path.exists(model_file):\n",
    "        model.load_state_dict(torch.load(model_file, map_location=device))\n",
    "        model.eval()\n",
    "        print(f\"Model loaded from {model_file}\")\n",
    "        return test(model, test_loader, device)\n",
    "    else:\n",
    "        print(\"No existing model found. Please train the model first.\")\n",
    "        return None\n",
    "\n",
    "# 调用测试函数\n",
    "# 确保在调用之前已经定义了 model_file, test_loader, INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT\n",
    "mse_loss, mae_loss, r2_score, rmse= load_and_test(model_file, test_loader, INPUT_DIM, D_MODEL, NUM_HEADS, FNN_DIM, NUM_LAYERS, DROPOUT)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python-3.9.10",
   "language": "python",
   "name": "python-3.9.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
